---
phase: 01-foundation-and-auth
plan: 02
type: execute
wave: 2
wave_type: SEQUENTIAL
depends_on: ["01-01"]
files_modified:
  - server/app/services/database.py
  - server/app/models/base.py
  - server/app/models/project.py
  - server/app/models/skill.py
  - server/app/models/habit.py
  - server/app/models/reflex.py
  - server/app/models/execution.py
  - server/app/models/billing.py
  - server/app/models/user.py
autonomous: true
difficulty: hard
enhancement_queries:
  - "Supabase Python SDK v2 service_role client with RLS context setting best practices?"
  - "Pydantic v2 models matching TypeScript interfaces for FastAPI request/response validation?"
  - "FastAPI Supabase integration patterns for multi-tenant SaaS with organization_id?"
  - "Deploying SQL migrations to Supabase via Python SDK or psql CLI?"

must_haves:
  truths:
    - "All 3 SQL migrations deploy successfully to Supabase"
    - "Pydantic models match TypeScript interfaces for all domain entities"
    - "Database service can execute queries against Supabase with proper auth context"
  artifacts:
    - path: "server/app/services/database.py"
      provides: "Supabase query helpers with auth context injection"
      exports: ["execute_query", "set_rls_context"]
    - path: "server/app/models/project.py"
      provides: "Project Pydantic models"
      contains: "ProjectCreate"
    - path: "server/app/models/skill.py"
      provides: "Skill Pydantic models"
      contains: "SkillCreate"
  key_links:
    - from: "server/app/services/database.py"
      to: "server/app/dependencies.py"
      via: "get_supabase dependency"
      pattern: "get_supabase"
    - from: "server/app/models/project.py"
      to: "database/001_project_creation_schema.sql"
      via: "schema alignment"
      pattern: "organization_id"
---

<objective>
Deploy SQL migrations to Supabase and create Pydantic models matching all database tables and TypeScript interfaces.

Purpose: Establish the data layer — database schema deployed with all tables, and Python models ready for CRUD operations. This is the foundation for all API endpoints.
Output: Deployed database schema, Pydantic models for all entities, database service with RLS-aware query helpers.
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/ARCHITECTURE.md
@.planning/research/PITFALLS.md
@database/001_project_creation_schema.sql
@database/002_skills_tables.sql
@database/003_habits_scheduler.sql
@.planning/phases/01-foundation-and-auth/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Deploy SQL migrations to Supabase</name>
  <files>
    server/app/services/database.py
  </files>
  <action>
    Deploy the 3 existing SQL migration files to Supabase:

    1. Read Supabase credentials from Keymaker NotebookLM or .env
    2. Use the Supabase Management API or psql to deploy migrations in order:
       - `database/001_project_creation_schema.sql` — projects, repos, members, ingestion, files
       - `database/002_skills_tables.sql` — skills, habits, reflexes, skill_executions
       - `database/003_habits_scheduler.sql` — cron functions, scheduler views

    3. Create `server/app/services/database.py` with:
       - `async def set_rls_context(client, user_id: str, org_id: str)` — calls `client.rpc('set_claim', {'claim': 'auth.uid', 'value': user_id})` or uses SET LOCAL statements via raw SQL
       - `async def execute_with_rls(client, user_id, org_id, query_fn)` — sets RLS context, executes query, returns result
       - Helper for SECURITY DEFINER functions when needed
       - Connection pooling considerations (use Supabase Pooler URL for multi-worker)

    4. Verify all tables exist by querying information_schema:
       ```sql
       SELECT table_name FROM information_schema.tables
       WHERE table_schema = 'public'
       ORDER BY table_name;
       ```
       Expected: projects, project_repositories, project_members, ingestion_progress, project_files, skills, habits, reflexes, skill_executions (plus any from migration 3)

    **IMPORTANT:** Use service_role key for migrations. Never use anon key for DDL.
    **IMPORTANT:** If migrations have already been run (tables exist), skip — don't error on "already exists".
  </action>
  <verify>
    ```bash
    python3 -c "
    from server.app.dependencies import get_supabase
    client = get_supabase()
    result = client.table('projects').select('id').limit(0).execute()
    print('projects table: OK')
    result = client.table('skills').select('id').limit(0).execute()
    print('skills table: OK')
    print('ALL MIGRATIONS VERIFIED')
    "
    ```
  </verify>
  <done>All 3 SQL migrations deployed, all tables queryable via Supabase client, database.py service created with RLS context helpers</done>
</task>

<task type="auto">
  <name>Task 2: Create Pydantic models matching TypeScript interfaces</name>
  <files>
    server/app/models/base.py
    server/app/models/project.py
    server/app/models/skill.py
    server/app/models/habit.py
    server/app/models/reflex.py
    server/app/models/execution.py
    server/app/models/billing.py
    server/app/models/user.py
    server/app/models/__init__.py
  </files>
  <action>
    Create Pydantic v2 models matching the SQL schema AND the frontend TypeScript interfaces.

    **Read first:** The frontend TypeScript types to ensure exact field name alignment:
    - `src/types/settings/billing.ts` — Plan, Subscription, PaymentMethod, Invoice, UsageMetric, BillingDetails
    - `src/services/projects.ts` — Project, Repository, TeamMember interfaces
    - `src/services/skills.ts` — Skill, SkillExecution interfaces
    - `src/services/habits.ts` — Habit interfaces
    - `src/services/reflexes.ts` — Reflex interfaces

    **server/app/models/base.py:**
    ```python
    from pydantic import BaseModel, ConfigDict
    from datetime import datetime
    from uuid import UUID

    class BaseSchema(BaseModel):
        model_config = ConfigDict(from_attributes=True)

    class TimestampMixin(BaseModel):
        created_at: datetime
        updated_at: datetime

    class PaginatedResponse(BaseModel):
        data: list
        total: int
        page: int
        page_size: int
        has_more: bool
    ```

    **For each domain entity (project, skill, habit, reflex, execution):**
    Create 3 models:
    - `{Entity}Create` — request body for POST (required fields only)
    - `{Entity}Update` — request body for PATCH (all fields Optional)
    - `{Entity}Response` — full entity returned in responses (all fields, including id, timestamps)

    **server/app/models/project.py example patterns:**
    ```python
    class ProjectCreate(BaseSchema):
        name: str = Field(min_length=3, max_length=50)
        description: str | None = None
        type: ProjectType = ProjectType.REPOSITORY
        chunking_strategy: ChunkingStrategy = ChunkingStrategy.SEMANTIC

    class ProjectResponse(BaseSchema, TimestampMixin):
        id: UUID
        user_id: UUID
        organization_id: UUID
        name: str
        description: str | None
        type: ProjectType
        status: ProjectStatus
        # ... all fields from SQL schema
    ```

    **CRITICAL:** Field names must use snake_case in Python but map to camelCase in JSON responses. Use `alias_generator = to_camel` in model_config, or configure FastAPI's response model to handle this.

    **server/app/models/billing.py:**
    Match the TypeScript Plan type exactly (Free, Pro, Teams, Enterprise tiers with limits: apiCalls, ingestions, storageGb, seats, oracleQueries). Use `Decimal` for all price fields, never float.

    **Enum definitions:** Create Python enums matching SQL ENUM types:
    - ProjectType, ProjectStatus, ProjectPrivacy, ChunkingStrategy, GitProvider, RepositoryStatus, ProjectMemberRole, IngestionPhase
    - SkillCategory, SkillOutputFormat, ExecutionStatus, ExecutionType, ReflexTriggerType
  </action>
  <verify>
    ```bash
    python3 -c "
    from server.app.models.project import ProjectCreate, ProjectResponse
    from server.app.models.skill import SkillCreate, SkillResponse
    from server.app.models.habit import HabitCreate, HabitResponse
    from server.app.models.reflex import ReflexCreate, ReflexResponse
    from server.app.models.billing import Plan, Subscription
    print('ALL MODELS IMPORT OK')
    p = ProjectCreate(name='Test Project')
    print(f'ProjectCreate validation: {p.name}')
    "
    ```
  </verify>
  <done>All Pydantic models created for projects, skills, habits, reflexes, executions, billing, and users. Models validate correctly and match both SQL schema and TypeScript interfaces.</done>
</task>

</tasks>

<verification>
1. All 3 SQL migrations deployed (tables queryable)
2. All Pydantic model files exist and import without error
3. ProjectCreate validates name length (3-50 chars)
4. Enum types match SQL ENUM definitions
5. database.py RLS context helpers are importable
</verification>

<success_criteria>
- All database tables exist in Supabase (verified by query)
- Pydantic models match SQL schema columns
- Pydantic models produce JSON matching TypeScript interface field names
- Database service provides RLS context injection
- All model imports work without circular dependency
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-and-auth/01-02-SUMMARY.md`
</output>
